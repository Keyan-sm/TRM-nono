Here is the Markdown conversion of the presentation slides.

# Tiny Recursive Model vs Frontier Model on Nonogram Puzzles

**Keyan Mikaili, Andre Keyser, Samik Bhinge**

---

## Slide 1: Title Slide

**Title:** Tiny Recursive Model vs Frontier Model on Nonogram Puzzles
**Authors:** Keyan Mikaili, Andre Keyser, Samik Bhinge

> **[Image Description]**
> Two grids depicting a 6x6 Nonogram puzzle.
> *   **(a) 6 x 6 Nonogram:** An empty grid with numerical clues on the top and left side.
> *   **(b) Solved Nonogram:** The same grid filled in with black squares to form a shape (resembling a small animal or figure) matching the clues.
> *   **Caption:** Figure 1: A small Nonogram and its unique solution.

---

## Slide 2: What is a Tiny Recursive Model (TRM)?

*   Published in October by Samsung
*   **Only 7M Parameters**
    *   Versus 1.7T+ Params in frontier models
*   Learns through recursive reasoning
    *   Update $z$ with current $x, y, z$
    *   Update $y$ with current $y, z$
*   Optimal for discrete, deterministic problems
*   Mimics human reasoning logic

> **[Image Description]**
> A block diagram illustrating the TRM architecture.
> *   **Left Block (Reasoning):** Shows a stack of "Normalization" -> "MLP" -> "Normalization" -> "MLP".
> *   **Right Block (Update):** Identical stack structure.
> *   **Flow:** The blocks output to a summation node (+).
> *   **Inputs/Outputs:**
>     *   **Input (x):** Question
>     *   **Prediction (y):** Answer (feeds into the blocks and is updated)
>     *   **Latent (z):** Reasoning (feeds into the blocks and is updated)
> *   **Loop:** An orange dotted line labeled "Update" shows the recursive feedback loop.

---

## Slide 3: What is a Tiny Recursive Model (TRM)? Why use a TRM?

*   Published in October by Samsung
*   Uses relatively few parameters (7M)
*   Learns through recursive reasoning
    *   Update $z$ with current $x, y, z$
    *   Update $y$ with current $y, z$
*   Mimics human reasoning on logic puzzles
*   **Simplicity**
    *   2 hidden layers vs. 95 hidden layers
    *   7 million parameters vs. 1.7 trillion parameters
*   **LLMs are not optimal for some tasks**
    *   One token is generated at a time
    *   A single incorrect token can make the solution incorrect
*   **TRMs use an intuitive approach to problem solving**
    *   Trial and error with different approaches
    *   Latent reasoning is improved rather than NN weights

> **[Image Description]**
> The same architecture diagram as Slide 2 is displayed at the bottom, highlighting the recursive update loop for Prediction ($y$) and Latent Reasoning ($z$).

---

## Slide 4: Motivation - Potential Advantages Over LLMs

*   **Simplicity**
    *   2 hidden layers vs. 95 hidden layers
    *   7 million parameters vs. 1.7 trillion parameters
*   **LLMs are not optimal for some tasks**
    *   One token is generated at a time
    *   A single incorrect token can make the solution incorrect
*   **TRMs use an intuitive approach to problem solving**
    *   Trial and error with different approaches
    *   Latent reasoning is improved rather than NN weights

---

## Slide 5: Nonograms

*   Simple logic puzzle, difficulty increases exponentially with size
    *   10x10 puzzle problem space $\rightarrow 2^{100}$ | 15x15 problem space $\rightarrow 2^{225}$
*   Boxes are marked based on the order of clues for each column and row
*   Represent a discrete, deterministic problem space

> **[Image Description]**
> A visual sequence demonstrating how a nonogram is solved.
> 1.  **Stage 1:** An empty 5x5 grid with clues (e.g., Row 1: "1 1", Row 2: "2 2").
> 2.  **Stage 2:** Partial completion. The center column "5" is filled in (vertical line of Xs).
> 3.  **Stage 3:** More rows are filled based on logic (crossing out impossible squares).
> 4.  **Stage 4 (Final):** A completed 15x15 nonogram depicting a bird (possibly an eagle or parrot) in pixel art.

---

## Slide 6: Research Question

*To what extent does learned recursive reasoning compare to algorithmic constraint satisfaction on nonogram puzzles, and what are the fundamental tradeoffs between these approaches?*

---

## Slide 7: Dataset Preparation and Baseline Implementation

*   We trained and tested our model using the dataset generated by the researchers in *Solving nonograms using Neural Networks* (Baudés Rubio et al., Jan. 2025)
*   The researchers generated training samples by transforming and reflecting random images into nonograms ($360k \rightarrow 10 \times 10$, $660k \rightarrow 15 \times 15$)
*   We modified the architecture and config from the Samsung paper to fit our data
    *   Global Batch Size ($768 \rightarrow 64$)
    *   Added Gradient Clipping
    *   Fixed Sequence Length

---

## Slide 8: TRM Architecture

*   **Iterative Reasoning:**
    *   H-Cycles; Outer loop for step generation
*   **State Refinement:**
    *   L-Cycles; Inner layers for data processing and computation
*   **Adaptive Computation:**
    *   Dynamic Halting; Decides on when to stop when confident

> **[Image Description]**
> A vertical flowchart of the TRM process.
> *   **Top:** "Cross-entropy loss" $\leftarrow$ "Reverse Embedding".
> *   **Core Block:** A stack repeated 4x containing "Add & Norm", "MLP", "Add & Norm", "Self-Attention".
> *   **Inputs:** Input ($x$), Prediction ($y$), Latent ($z$).
> *   **Steps:**
>     *   Step 1, 2, ..., n: Update $z$ given $x, y, z$ (Improve the latent $z$).
>     *   Step n+1: Update $y$ given $y, z$ (Improve the prediction $y$).
>     *   Applied $N_{sup} = 16$ times.
> *   **Bottom Diagram:** Shows the flow from "True y" and "Updated y" leading to "Cross-Entropy Loss".

---

## Slide 9: Our Architecture & Config

*   **Dataset:** $10 \times 10$ Nonograms (361,094 Training Samples)
*   **Hardware:** Vast.ai Cloud GPU (NVIDIA RTX 4090)
*   **Batch Size:** 256
*   **Precision:** Float16 (Mixed Precision)
*   **Training Time:** 80 minutes; Convergence in 8 epochs

> **[Image Description]**
> A screenshot of the Vast.ai console showing the instance specifications:
> *   **GPU:** 1x RTX 4090 (Verified)
> *   **Performance:** 81.4 TFLOPS, VRAM 24.0 GB
> *   **CPU:** AMD EPYC 7C13 64-Core
> *   **Cost:** $0.299/hr

---

## Slide 10: 10x10 Results & Comparison

**Tiny Recursive Model**
*   **Test Set Size:** 15,274 puzzles
*   **Performance:**
    *   Accuracy: 0.998
    *   Exact Match: **0.96**
    *   Loss: converged to ~0.0001
*   **Inference Speed (CPU)**
    *   Mean Time: 2134.89 ms
    *   Median Time: 2185.65 ms (2.1s)
    *   Std Dev: 546.37 ms

**Gemini 3 Pro (High)**
*   **Test Set Size:** 30 puzzles*
*   **Performance:**
    *   Exact Match: **0.87**
*   **Inference Speed (Cloud)**
    *   Mean Time: 132500.0 ms (2.2 min)
    *   Median Time: 97400.0 ms (1.6 min)
    *   $t \propto acc^{-1}$

> **[Image Description]**
> Small text snippets showing raw output data for "Final Solution Grid" and timing stats:
> *   Exact Match = 1.0, Inference Speed = 81100 ms
> *   Exact Match = 0.0, Inference Speed = 331300 ms
> *   *Footnote:* *Arbitrary test set due to Gemini 3 (High) API constraints

---

## Slide 11: 15x15 Results & Comparison

**Tiny Recursive Model**
> **[Image Description]**
> A dashboard of 6 line graphs (WandB style) tracking training progress.
> *   **test.exact_accuracy:** Rises sharply and plateaus around 0.65.
> *   **test.accuracy:** Rises to approx 0.975.
> *   **test.lm_loss:** Drops significantly from 0.11 to below 0.06.
> *   **test.q_halt_accuracy:** Rises to 0.91.
> *   **train/exact_accuracy:** Highly volatile/noisy data, oscillating between 0.2 and 1.0.
> *   **train/q_halt_accuracy:** Highly volatile/noisy data.

**Gemini 3 Pro (High)**
*   **Test Set Size:** 30 puzzles*
*   **Performance:**
    *   Exact Match: 0.52

---

## Slide 12: Conclusion

| TRM | Gemini 3 Pro |
| :--- | :--- |
| - Trained for specific task on specific data | - Viable on much more tasks than TRM, but outperformed by TRM on logical puzzles |
| - Recursively solves problems similar to humans | - Needs large computational power to train (TPU) |
| - Training far less computationally intensive | |

---

## Slide 13: Conclusion

*   **Demonstrated outperformance**
    *   Our Narrowly trained TRM outperforms generalized SOTA models
    *   Generally strong in discrete, deterministic problem spaces
    *   96% accuracy vs 87% on $10 \times 10$ Nonograms
    *   80% accuracy vs 52% on $15 \times 15$ Nonograms*
    *   50-70x faster inference
*   **Future Work**
    *   Many discrete, deterministic problems in the real world
    *   Constraint Satisfaction Problems (Scheduling, Crosswords)
    *   Pathfinding (self-driving car route)
    *   Mathematical Reasoning

---

## Slide 14: References

*   **Substack Article:** [https://vizuara.substack.com/p/tiny-recursive-model-trm](https://vizuara.substack.com/p/tiny-recursive-model-trm)
*   **Solving Nonograms Using Neural Networks:** [https://arxiv.org/abs/2501.05882](https://arxiv.org/abs/2501.05882)
*   **Less is More: Recursive Reasoning with Tiny Networks:** [https://arxiv.org/abs/2510.04871](https://arxiv.org/abs/2510.04871)

---

## Slide 15: Task Configuration (JSON)

> **[Image Description]**
> A screenshot of a JSON configuration object.
>
> ```json
> {
>   "task": "solve_nonogram",
>   "method": "pure_logical_reasoning",
>   "restrictions": [
>     "no_code",
>     "no_scripts"
>   ],
>   "format": {
>     "filled": "X",
>     "empty": "."
>   },
>   "puzzle_data": {
>     "dimensions": "10x10",
>     "row_clues": [[2, 2], [7], [1, 2, 2], [1, 6], [1, 1, 1, 3], ...],
>     "col_clues": [[1, 1], [1, 3, 1], [1, 3, 2], [1, 1, 2], [5, 3], ...]
>   },
>   "output_requirements": [
>     "step_by_step_reasoning",
>     "final_solved_grid"
>   ]
> }
> ```

---

## Slide 16: Training Loss Graph

> **[Image Description]**
> A chart labeled `train/lm_loss`. The curve shows a sharp descent from ~0.4 to ~0.15 initially, then a noisy but gradual decline to ~0.1 over 50k steps.

---

## Slide 17: Test Metrics Graphs

> **[Image Description]**
> Four charts showing testing metrics over 50k steps.
> 1.  **test.q_halt_loss:** Decreases from 0.32 to ~0.22.
> 2.  **test.lm_loss:** Smooth curve decreasing from 0.11 to ~0.06.
> 3.  **test.steps:** Flat line at roughly 16 steps (indicates the model is using max steps or a fixed step count).
> 4.  **test.q_halt_accuracy:** Increases from 0.86 to 0.91.
> 5.  **test.exact_accuracy:** Increases from ~0.35 to 0.65.
> 6.  **test.accuracy:** Increases from ~0.96 to ~0.978.

---

## Slide 18: Training Metrics Graphs

> **[Image Description]**
> Six charts showing training metrics. These are characterized by extreme noise/oscillation (the green lines fill almost the entire vertical space of the graph).
> 1.  **train/steps:** Oscillates between 0 and 15.
> 2.  **train/q_halt_loss:** Noisy, average around 0.2.
> 3.  **train/q_halt_accuracy:** Oscillates between 0 and 1.
> 4.  **train/lr:** Smooth curve showing learning rate decay from 0.0001 to near 0.
> 5.  **train/lm_loss:** Sharp drop at the start, then flat/stable low loss.
> 6.  **train/exact_accuracy:** Oscillates wildly between 0 and 1.

---

## Slide 19: Training Count & Accuracy

> **[Image Description]**
> Two charts:
> 1.  **train/count:** Solid block of green, indicating a constant value or high density of data points at 1.0.
> 2.  **train/accuracy:** Starts noisy but quickly converges to a solid block near 1.0, indicating the model learned the training data perfectly.

---

## Slide 20: Architecture Diagram (Detailed)

**Key Components:**
*   **H-Cycles:** The outer loop where the model "thinks" for multiple steps.
*   **L-Cycles:** The inner transformer layers that process the state.
*   **Dynamic Halting:** The model can decide when it has "thought enough" and output the answer.

> **[Image Description]**
> A flowchart titled "Architecture Diagram".
> *   **Input:** "Input Clues" $\rightarrow$ "Embedding Layer".
> *   **Loop (Recursive Reasoning Loop - I):**
>     *   "Initial Carry State" $\rightarrow$ "L-Cycle - Transformer Block".
>     *   Decision Diamond: "Halt?".
>     *   **No:** $\rightarrow$ "Update Carry State" $\rightarrow$ Back to "L-Cycle".
>     *   **Yes:** $\rightarrow$ "Output Head" $\rightarrow$ "Predicted Grid".

---

## Slide 21: Experimental Setup & Results

**3. Experimental Setup**
*   **Dataset:** 10x10 Nonograms (361,094 Training Samples)
*   **Hardware:** Vast.ai Cloud GPU (NVIDIA RTX 4090)
*   **Batch Size:** 256 (Optimized)
*   **Precision:** Float16 (Mixed Precision)
*   **Training Time:** ~1 hour (Converged in 5 epochs)

**4. Results**
The model's performance was exceptional, solving the task completely.
**Performance Metrics (Test Set Size: 15,274 puzzles)**
*   **Accuracy:** 1.0 (100%) - Every single cell in the grid was predicted correctly.
*   **Exact Match:** 1.0 (100%) - Every puzzle in the test set was solved perfectly.
*   **Loss:** ~0.0001 - Near-zero error, indicating high confidence.

> **[Text Note on Slide]**
> *Handwritten style note:* "add this in footnote for 10x10: --- Inference Speed Results (CPU) --- Mean Time: 2134.89 ms, Median Time: 2185.65 ms, Std Dev: 346.37 ms, Min Time: 1618.37 ms, Max Time: 3877.30 ms"

**Inference Speed (CPU)**
*   Mean Time: 2.13 seconds / puzzle
*   Median Time: 2.19 seconds / puzzle
*   **Comparison with LLM Baseline (Gemini):** TRM is approximately 70-100x faster and achieves perfect accuracy (100% vs 90%).

---

## Slide 22: Architecture & Data Differences (Tables)

**Table 1: Key Differences**

| Feature | Samsung (Original) | TRM 15x15 (Ours) | Impact |
| :--- | :--- | :--- | :--- |
| **Global Batch Size** | 768 | 64 | **12x Difference.** Smaller batches have much "noisier" gradients. |
| **Gradient Clipping** | None | 1.0 (Proposed) | **Essential.** Without clipping, the noise from the small batch size causes the loss to explode (NaN). |
| **Learning Rate** | 1e-4 | 3e-5 (Current) | We lowered it to try to fix stability, but batch size noise was likely the root cause. |

> **IMPORTANT:**
> **Why this matters:** Neural networks average the gradients over the batch.
> *   **Batch 768:** The average is very stable and smooth.
> *   **Batch 64:** The average is noisy and erratic. Occasionally, a "bad" batch will produce a massive gradient spike that breaks the model (NaN).
> **Gradient Clipping** fixes this by capping those spikes, allowing us to train safely with the smaller batch size.

**Table 2: Architecture & Data Differences**

| Feature | Samsung (Original) | TRM 15x15 (Ours) | Notes |
| :--- | :--- | :--- | :--- |
| **Dataset** | ARC (Abstract Reasoning) | Nonograms 15x15 | Nonograms have longer sequences (465) than typical ARC tasks. |
| **Sequence Length** | Variable (Short) | 465 | Longer sequences make gradients more prone to exploding (Vanishing/Exploding gradient problem). |
| **Hidden Size** | 512 | 384 (Config) / 512 (Default) | We experimented with 384 to save memory, but 512 is the paper default. |
| **Recursion (H_cycles)** | 3 | 5 (Config) / 3 (Default) | We increased this to 5 to give the model more "thinking time", but it adds depth and instability. |
| **Heads** | 8 | 6 (Config) / 8 (Default) | Matched to hidden size. |

---

## Slide 23: Debugging Journey (Part 1)

**TRM 15x15 Nonogram Training: Debugging Report**

**Executive Summary**
*   **Problem:** TRM model training for 15x15 Nonograms consistently crashed with NaN loss at Step 17.
*   **Root Cause:** Two compounding numerical instability issues:
    1.  `bfloat16` precision insufficient for recursive model architecture.
    2.  `epsilon=1e-30` too small for `float32`, causing gradient explosion in loss function.
*   **Solution:**
    *   Switch to `float32` precision.
    *   Increase epsilon to `1e-8` in loss function.
*   **Result:** ✅ Successful training - loss decreased from 4.0 $\rightarrow$ 1.0, accuracy reached 63%.

**Timeline of Debugging Journey**

**Phase 1: Initial Investigation (Batch Size Hypothesis)**
*   Hypothesis: Small batch size (64 vs Samsung's 768) causes noisy gradients.
*   Tested: Gradient clipping (`clip_grad_norm=1.0`)
*   Result: ❌ Still crashed at Step 17
*   Learning: Gradient clipping helps but doesn't solve root cause.

**Phase 2: Learning Rate Tuning**
*   Hypothesis: Learning rate too aggressive for small batch.
*   Tested:
    *   `lr=1e-4` (Samsung default) $\rightarrow$ `1e-5` $\rightarrow$ `2e-8`
    *   `lr_warmup_steps=100` $\rightarrow$ `1000`
*   Result: ❌ Even with `lr=2e-8`, still crashed at Step 17.
*   Learning: LR not the culprit; issue is deeper.

**Phase 3: Data Validation**
*   Hypothesis: Corrupted or malformed input data.
*   Action: Created `inspect_data.py` to verify:
    *   Shape: ✅ (64, 465) correct
    *   Dtype: ✅ int64 correct
    *   Range: ✅ [0, 15] within vocab
    *   NaNs/Infs: ✅ None found (tested 20 batches including Batch 17)
*   Result: ✅ Data is clean.
*   Learning: NaN originates in model/loss, not data.

---

## Slide 24: Debugging Journey (Part 2)

**Phase 4: Model Architecture Analysis**
*   Investigation: Reviewed `trm.py`
*   Findings:
    *   Uses Post-Normalization (less stable than Pre-Norm)
    *   Truncated backpropagation: Only last `H_cycle` gets gradients
    *   Carry state explicitly `.detach()`ed between steps
    *   `bfloat16` used for forward pass
    *   `q_head` initialized with zeros (weights) and -5 (bias)
    *   `RMSNorm` used (casts to `float32` internally, so stable)
*   Result: ℹ️ Identified `bfloat16` as potential issue.

**Phase 5: Anomaly Detection**
*   Action: Enabled `torch.autograd.set_detect_anomaly(True)` in `pretrain.py`
*   Traceback Revealed: `RuntimeError: Function 'ReciprocalBackward0' returned nan values in its 0th output.` (File "models/losses.py", line 14: `1/(1-x+epsilon)`)

**Root Cause Found:**
*   Function `s(x, epsilon=1e-30)` in `losses.py`
*   `epsilon=1e-30` is meaningless for `float32` (precision ~7 digits)
*   When `1-x+epsilon = 0`, the reciprocal `1/y` explodes.
*   Gradient of `1/y` is `-1/y^2`, which becomes NaN when `y` is tiny.

**Why it crashed at Step 16/17 specifically:**
*   Step 16 was first time a batch halted (`train/count=1.0`)
*   Model update from Step 16 caused extreme logits in Step 17
*   Extreme logits $\rightarrow$ `1-x+1e-30 = 0` $\rightarrow$ gradient explosion

**The Final Fix**

**Change 1: Switch to `float32` Precision**
*   File: `config/nonogram_15x15.yaml`
    ```yaml
    arch:
      - forward_dtype: "bfloat16"
      + forward_dtype: "float32"
    ```
*   Rationale: `bfloat16` has wider range but less precision (3 decimal digits). Recursive models accumulate errors across steps. `float32` provides 7 decimal digits, sufficient for stability.

**Change 2: Increase Epsilon**
*   File: `models/losses.py`
    ```python
    - def s(x, epsilon=1e-30):
    + def s(x, epsilon=1e-8):
    ```
*   Rationale: `1e-8` is meaningful for `float32`. Prevents `1/(1-x+epsilon)` from exploding when `x=1`. Still small enough to not affect loss semantics.

---

## Slide 25: Final Configuration & Results

**Final Configuration**
```python
# Key Settings
lr: 1e-5                # Reduced from 1e-4 for stability
lr_warmup_steps: 1000   # Increased from 100
global_batch_size: 64   # Limited by GPU memory
epochs: 5               # PoC target

# Model Architecture (Samsung defaults)
hidden_size: 512
num_heads: 8
H_cycles: 3
L_cycles: 4
L_layers: 2

# CRITICAL FIXES
forward_dtype: "float32" # Changed from bfloat16
# losses.py: epsilon: 1e-8 # Changed from 1e-30
```

**Results**
Training Metrics (Step 226):
*   **Loss:** 4.0 $\rightarrow$ 1.48 (63% reduction)
*   **Accuracy:** 0% $\rightarrow$ 63.3%
*   **Exact Solve Rate:** First success at Step 192 (1.6%)
*   **Status:** ✅ Stable, no crashes

**Key Observations:**
*   Q-learning halting mechanism shows occasional spikes (normal learning dynamics).
*   Model successfully learning nonogram constraints.
*   Training continues without numerical issues.

**Lessons Learned**
1.  `bfloat16` is not always safe - recursive/iterative models need higher precision.
2.  Epsilon values matter - `1e-30` is useless for `float32`, use `1e-6` to `1e-8`.
3.  Anomaly detection is invaluable - `torch.autograd.set_detect_anomaly(True)` pinpointed exact issue.
4.  Data validation first - rule out data issues before diving into model internals.
5.  Gradient clipping helps but isn't a silver bullet - addresses symptoms, not root cause.
6.  Learning rate tuning has limits - can't fix fundamental numerical instability.

**What Didn't Work (Dead Ends)**

| Attempt | Reasoning | Result |
| :--- | :--- | :--- |
| Aggressive LR reduction (2e-8) | Thought small steps would prevent instability | ❌ Still crashed |
| Gradient clipping only | Assumed exploding gradients were the issue | ❌ Masked symptoms |
| Increased warmup steps | Hoped gradual LR increase would help | ❌ No effect |
| Reverting to Samsung hyperparams | Thought config mismatch was culprit | ❌ Still crashed |

---

## Slide 26: Training Crash (OOM)

> **[Image Description]**
> A terminal screenshot showing the process killed.
> `Processing batch 221: test`
> `Killed`
> `Error: API key must have 40+ characters...`
> `Training Crashed due to OOM (Out of Memory) during Evaluation.`

**The good news:** Training was working! It reached Step 226 and started evaluation.
**The bad news:** It ran out of memory during evaluation (Batch 221/239).

**Why it crashed:**
1.  **Anomaly Detection:** I left `torch.autograd.set_detect_anomaly(True)` on. This consumes huge amounts of memory, especially during evaluation loops.
2.  **Evaluation Frequency:** It seems to be evaluating very frequently (or the first epoch ended early for some reason).

**The Fixes Applied:**
1.  **Disabled Anomaly Detection:** Removed the memory-hogging debug flag.
2.  **Added `empty_cache()`:** Forces GPU memory cleanup during evaluation.
3.  **Enabled Checkpointing:** Set `checkpoint_path` so if it crashes again, you can resume!

---

## Slide 27: Recommendations & Files Modified

**Recommendations for Future Training**
1.  Always use `float32` for recursive models unless memory is critical.
2.  Validate epsilon values match your dtype precision.
3.  Enable anomaly detection early when debugging NaNs.
4.  Monitor first halting events - often trigger instabilities.
5.  Keep gradient clipping as a safety net, even if not the fix.
6.  Test with small LR first but don't expect it to fix numerical issues.

**Files Modified**

**Core Fixes**
*   `config/nonogram_15x15.yaml` - Added `forward_dtype: "float32"`
*   `models/losses.py` - Changed `epsilon=1e-30` $\rightarrow$ `1e-8`

**Debugging Aids**
*   `pretrain.py` - Added gradient clipping, debug prints
*   `inspect_data.py` - Created for data validation

**Debugging Duration:** ~8 hours
**Total Runs:** 12+ failed attempts
**Final Status:** ✅ **Training Successful**

---

## Slide 28: WandB Runs Overview

> **[Image Description]**
> A spreadsheet view from Weights & Biases (WandB) listing 12 runs.
> *   Status column shows many "Failed" and "Crashed" runs.
> *   The last run (top of list) "Tiny...giraffe" shows state "Failed" but progressed further than others.
> *   Columns show Architecture (3, 5), Precision (`float32`, `bfloat16`), Hidden Size (384, 512), and Learning Rates.

---

## Slide 29: End of Presentation

> **[Image Description]**
> Blank white slide.