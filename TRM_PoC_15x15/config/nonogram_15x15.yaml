# Nonogram 15x15 training config

defaults:
  - arch: trm
  - _self_

hydra:
  output_subdir: null

# Data path
data_paths: ['dataset/nonogram_15x15']
data_paths_test: []

evaluators:
  - name: nonogram@NonogramEvaluator


# Names
project_name: "TRM-15x15"

# Hyperparams - Training
global_batch_size: 64 # Same as 10x10, should fit on 4090

epochs: 5
eval_interval: 1
checkpoint_every_eval: True
checkpoint_path: "checkpoints/nonogram_15x15"

lr: 1e-4 # Restored to original value after float32 fix
lr_min_ratio: 0.1
lr_warmup_steps: 1000 # Increased from 100 for gentler start

beta1: 0.9
beta2: 0.95
weight_decay: 0.1
puzzle_emb_weight_decay: 0.1

puzzle_emb_lr: 1e-3

seed: 42
min_eval_interval: 0

ema: True
ema_rate: 0.999
freeze_weights: False

# Architecture overrides
arch:
  hidden_size: 512 # Reverted to Samsung default
  num_heads: 8     # Reverted to Samsung default
  expansion: 4
  puzzle_emb_ndim: 0
  forward_dtype: "float32"
  puzzle_emb_len: 0
  
  # Recursion depth
  H_cycles: 3      # Reverted to Samsung default
  L_cycles: 4
  L_layers: 2
